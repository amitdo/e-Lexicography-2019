{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguistic annotation with `Python`\n",
    "\n",
    "`Python` is a highly versatile programming language which offers a great number of\n",
    "libraries which greatly support your work as digital lexicographer.\n",
    "\n",
    "This notebook is supposed to illustrate the different levels of automatic linguistic\n",
    "annotation used in the course.\n",
    "\n",
    "## Libraries used in the course\n",
    "\n",
    "We use the wonderful [Natural Language Toolkit](https://www.nltk.org/) which comes\n",
    "with a great set of tools and resources. In addition, [spaCy](https://spacy.io/) is\n",
    "used. It has a smaller range of functionalities but is a lot faster and uses state-\n",
    "of-the-art algorithms (namely deep learning approaches).\n",
    "\n",
    "## Setup\n",
    "\n",
    "We assume that you have a working `Python3` installation. The following instructions\n",
    "are tailored to Linux and MacOS but should -- with minor modifications -- work on\n",
    "Windows as well.\n",
    "\n",
    "### `pip`\n",
    "\n",
    "`pip` is the package manager for `Python`. From version 3.4 on, it ships with `Python`. \n",
    "\n",
    "### `virtualenv`\n",
    "\n",
    "`virtualenv` allows you to setup local (and clean) `Python` environments. It may be\n",
    "installed via\n",
    "```sh\n",
    "[sudo] pip install virtualenv\n",
    "```\n",
    "\n",
    "Create a virtual environement in a subdirectory of your choice (e.g. `env`) using\n",
    "```sh\n",
    "virtualenv -p python3 env\n",
    "```\n",
    "\n",
    "and activate it.\n",
    "```sh\n",
    ". env/bin/activate\n",
    "```\n",
    "\n",
    "### `NLTK` and `spaCy`\n",
    "\n",
    "3rd party Python packages (including `NLTK` and `spaCy`) may best be installed using `pip`:\n",
    "```sh\n",
    "(env) pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## Testing\n",
    "\n",
    "Now, we are ready to roll. Start `Python`:\n",
    "```sh\n",
    "(env) python\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `NLTK`\n",
    "\n",
    "`NLTK` itself provides a high-level API to numerous NLP tools. Before we can use them, they\n",
    "have to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kmw/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to do some work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Das', 'z.B', '.', 'ist', 'ein', 'Testsatz', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Das z.B. ist ein Testsatz.\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
