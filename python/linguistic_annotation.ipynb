{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguistic annotation with `Python`\n",
    "\n",
    "`Python` is a highly versatile programming language which offers a great number of\n",
    "libraries which greatly support your work as digital lexicographer.\n",
    "\n",
    "This notebook is supposed to illustrate the different levels of automatic linguistic\n",
    "annotation used in the course.\n",
    "\n",
    "## Libraries used in the course\n",
    "\n",
    "We use the wonderful [Natural Language Toolkit](https://www.nltk.org/) which comes\n",
    "with a great set of tools and resources. In addition, [spaCy](https://spacy.io/) is\n",
    "used. It has a smaller range of functionalities but is a lot faster and uses state-\n",
    "of-the-art algorithms (namely deep learning approaches).\n",
    "\n",
    "## Setup\n",
    "\n",
    "We assume that you have a working `Python3` installation. The following instructions\n",
    "are tailored to Linux and MacOS but should -- with minor modifications -- work on\n",
    "Windows as well.\n",
    "\n",
    "### `pip`\n",
    "\n",
    "`pip` is the package manager for `Python`. From version 3.4 on, it ships with `Python`. \n",
    "\n",
    "### `virtualenv`\n",
    "\n",
    "`virtualenv` allows you to setup local (and clean) `Python` environments. It may be\n",
    "installed via\n",
    "```sh\n",
    "[sudo] pip install virtualenv\n",
    "```\n",
    "\n",
    "Create a virtual environement in a subdirectory of your choice (e.g. `env`) using\n",
    "```sh\n",
    "virtualenv -p python3 env\n",
    "```\n",
    "\n",
    "and activate it.\n",
    "```sh\n",
    ". env/bin/activate\n",
    "```\n",
    "\n",
    "### `NLTK` and `spaCy`\n",
    "\n",
    "3rd party Python packages (including `NLTK` and `spaCy`) may best be installed using `pip`:\n",
    "```sh\n",
    "(env) pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## Testing\n",
    "\n",
    "Now, we are ready to roll. Start `Python`:\n",
    "```sh\n",
    "(env) python\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `NLTK`\n",
    "\n",
    "`NLTK` itself provides a high-level API to numerous NLP tools. Before we can use them, they\n",
    "have to be installed.\n",
    "\n",
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kmw/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to do some work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'shows', 'NLTK', \"'s\", 'potentials', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This shows NLTK's potentials.\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morphological analysis\n",
    "\n",
    "Let's go for stemming!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "show\n",
      "nltk\n",
      "'s\n",
      "potenti\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "for token in tokens:\n",
    "    print(stemmer.stem(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very impressive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/kmw/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "show\n",
      "NLTK\n",
      "'s\n",
      "potential\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for token in tokens:\n",
    "    print(lemmatizer.lemmatize(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PoS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This', 'DT')\n",
      "('shows', 'VBZ')\n",
      "('NLTK', 'NNP')\n",
      "(\"'s\", 'POS')\n",
      "('potentials', 'NNS')\n",
      "('.', '.')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/kmw/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "for pos_tag in pos_tags:\n",
    "    print(pos_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what about the tagset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to /Users/kmw/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('tagsets')\n",
    "nltk.help.upenn_tagset('NNS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no German tagger available with NLTK. Let's try to train one.\n",
    "First, we have to obtain a training corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tigercorpus-2.2.conll09.tar.gz', <http.client.HTTPMessage at 0x10cd40828>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/TIGERCorpus/download/tigercorpus-2.2.conll09.tar.gz'\n",
    "from urllib import request\n",
    "request.urlretrieve(url, 'tigercorpus-2.2.conll09.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, uncompress it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "tar = tarfile.open('tigercorpus-2.2.conll09.tar.gz', mode='r:gz')\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read it with NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('``', '$('), ('Ross', 'NE'), ('Perot', 'NE'), ('wäre', 'VAFIN'), ('vielleicht', 'ADV'), ('ein', 'ART'), ('prächtiger', 'ADJA'), ('Diktator', 'NN'), (\"''\", '$(')]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "corp = nltk.corpus.ConllCorpusReader('.', 'tiger_release_aug07.corrected.16012013.conll09',\n",
    "                                     ['ignore', 'words', 'ignore', 'ignore', 'pos'],\n",
    "                                     encoding='utf-8')\n",
    "print(corp.tagged_sents()[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Allerdings', 'ADV'), ('glaubt', 'VVFIN'), ('fast', 'ADV'), ('die', 'ART'), ('Hälfte', 'NN'), ('der', 'ART'), ('Chief', 'FM'), ('Executives', 'FM'), (',', '$,'), ('daß', 'KOUS'), ('Perot', 'NE'), ('durchaus', 'ADV'), ('Chancen', 'NN'), ('habe', 'VAFIN'), (',', '$,'), ('die', 'ART'), ('Wahl', 'NN'), ('im', 'APPRART'), ('November', 'NN'), ('zu', 'PTKZU'), ('gewinnen', 'VVINF'), (',', '$,'), ('wenn', 'KOUS'), ('er', 'PPER'), ('denn', 'ADV'), ('kandidiert', 'VVFIN'), ('.', '$.')]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "tagged_sents = corp.tagged_sents()[0:1000]\n",
    "\n",
    "# set a split size: use 90% for training, 10% for testing\n",
    "split_perc = 0.1\n",
    "split_size = int(len(tagged_sents) * split_perc)\n",
    "train_sents, test_sents = tagged_sents[split_size:], tagged_sents[:split_size]\n",
    "print(train_sents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Das', 'NN'), ('ist', 'VAFIN'), ('schön', 'ADV'), ('.', '$.')],\n",
       " [('Funktioniert', 'VVFIN'), ('es', 'PPER'), ('?', '$.')]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import CRFTagger\n",
    "\n",
    "ct = CRFTagger()\n",
    "ct.train(train_sents,'model.crf.tagger')\n",
    "ct.tag_sents([['Das','ist','schön', '.'], ['Funktioniert','es','?']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Evaluate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8876651982378855"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collocations\n",
    "\n",
    "To start with identifying collocations, we need a corpus to work with. Luckily, `NLTK` provides a number of them. We choose the prime father of corpora, the Brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/kmw/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by searching words with the concordance function. For this, we create a `Text` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 30 of 38 matches:\n",
      "a , Mont. , have a new baby . Their mother is Mrs. Camilla Alsop Wendell . Mr.\n",
      "n gown , and it's fitted , says her mother . Also , invitations have been addr\n",
      "also has a number of parolees to `` mother '' , watching to see that they do n\n",
      " College in Wellesley , Mass. . Her mother is the former Miss Stella Hayward .\n",
      " in the `` maskers' dances '' . The mother of young queen , Mrs. G. Henry Pier\n",
      "e fair . Police said the children's mother , Mrs. Eleanor Somerville , was vis\n",
      "at her Portland home by her widowed mother , 80 , her maiden aunt , also 80 an\n",
      "y of six surviving children , whose mother died yesterday as the aftermath to \n",
      "ay night at the flat of her widowed mother , Mrs. Mary Pankowski , in the adjo\n",
      "rch , 31978 Mound , in Warren . The mother and daughter , who will be buried s\n",
      "Kowalski girls present held for her mother , because the flat lacked electrici\n",
      ", and we must stay together the way Mother wanted '' , Kowalski said in tellin\n",
      "born in County Down , Ireland . Her mother was a Greer and her father's family\n",
      "'t remember when I didn't pester my mother to teach me to cook '' . He was in \n",
      " H. Reese , wife of an engineer and mother of a 23-year-old son , was awarded \n",
      "coconut filling and vanilla glaze . Mother of five Mrs. Oliver is mother of fi\n",
      "aze . Mother of five Mrs. Oliver is mother of five children and wife of a mach\n",
      "baby , she is getting married . Her mother , now dead , was my good friend and\n",
      "g meaningful to her , something her mother would wish said . For a while there\n",
      "ok from here at this point . Is the mother of an `` autistic '' child at fault\n",
      " as if they were people . ) Did his mother make him this way ? ? Some people b\n",
      "n , is to a large extent inborn . A mother can help a child adapt to his diffi\n",
      "ionally disturbed or autistic . The mother of a difficult child can do a great\n",
      "ote : total disinterest `` . As the mother of an autistic child who is lacking\n",
      "to them or because of the way their mother treats them . But I do and my psych\n",
      "s uncomfortable for him '' ! ! This mother is quite correct . As a rule , the \n",
      "`` Remember Fanny Brice promised my mother she would look after me on the road\n",
      "e him confused and unmoved . If his mother loves him , he clings to that love \n",
      "tent in the 2-year-old . What can a mother do then to prevent misbehavior ? ? \n",
      "recarious period of development the mother should continue to influence the gr\n",
      "None\n",
      "Displaying 10 of 38 matches:\n",
      "r mother i\n",
      "r mother .\n",
      "` mother '\n",
      "r mother i\n",
      "e mother o\n",
      "s mother ,\n",
      "d mother ,\n",
      "e mother d\n",
      "d mother ,\n",
      "e mother a\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(brown.words(brown.fileids()[0:100]))\n",
    "print(text.concordance('mother', lines=30))\n",
    "print(text.concordance('mother', lines=10, width=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting collocations is easy!\n",
    "\n",
    "1. Import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a measures object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a finder object which does the hard work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_finder = BigramCollocationFinder.from_words(brown.words(brown.fileids()[0:10]))\n",
    "trigram_finder = TrigramCollocationFinder.from_words(brown.words(brown.fileids()[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Inspect the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('$115,000', 'annually'), ('$157,460', 'yearly'), ('100,000', 'recipients'), ('12,000', 'babies'), ('1311', 'acre'), ('1409', 'SW'), ('182', 'scholastics'), ('330', 'Woodland'), ('Abe', 'Stark'), ('Al', 'Ullman')]\n",
      "\n",
      "[('$115,000', 'annually'), ('$157,460', 'yearly'), ('100,000', 'recipients'), ('12,000', 'babies'), ('1311', 'acre'), ('1409', 'SW'), ('182', 'scholastics'), ('330', 'Woodland'), ('Abe', 'Stark'), ('Al', 'Ullman')]\n",
      "\n",
      "[('.', 'The'), ('of', 'the'), ('.', 'He'), (\"''\", '.'), ('has', 'been'), ('in', 'the'), ('United', 'States'), ('would', 'be'), ('will', 'be'), ('more', 'than')]\n",
      "\n",
      "[('.', 'The'), ('of', 'the'), ('in', 'the'), (\"''\", '.'), ('.', 'He'), ('on', 'the'), ('.', '``'), ('for', 'the'), (\"''\", ','), ('has', 'been')]\n",
      "\n",
      "[('12,000', 'babies', 'born'), ('1409', 'SW', 'Maplecrest'), ('Cape', 'Cod', 'writing'), ('Community', 'visiting', 'nurse'), ('Contempt', 'proceedings', 'originally'), ('Defends', 'Ike', 'Earlier'), ('Edgar', 'Hoover', 'presides'), ('Emerald', 'Empire', 'Kiwanis'), ('Inspections', 'Barnet', 'Lieberman'), ('Irish', 'Counties', 'Feis')]\n",
      "\n",
      "[('12,000', 'babies', 'born'), ('1409', 'SW', 'Maplecrest'), ('Cape', 'Cod', 'writing'), ('Community', 'visiting', 'nurse'), ('Contempt', 'proceedings', 'originally'), ('Defends', 'Ike', 'Earlier'), ('Edgar', 'Hoover', 'presides'), ('Emerald', 'Empire', 'Kiwanis'), ('Inspections', 'Barnet', 'Lieberman'), ('Irish', 'Counties', 'Feis')]\n",
      "\n",
      "[(\"''\", '.', 'The'), ('said', '.', 'The'), ('.', 'The', 'President'), ('project', '.', 'The'), ('year', '.', 'The'), ('.', 'The', 'jury'), ('.', 'The', 'new'), ('years', '.', 'The'), ('.', 'The', 'petition'), ('Laos', '.', 'The')]\n",
      "\n",
      "[(',', 'he', 'said'), ('the', 'United', 'States'), (\"''\", ',', 'he'), ('.', 'He', 'said'), ('he', 'said', ','), ('said', ',', '``'), (\"''\", '.', 'The'), (\"''\", ',', 'the'), (\"''\", '.', 'He'), ('he', 'said', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(bigram_finder.nbest(bigram_measures.pmi, 10))\n",
    "print()\n",
    "print(bigram_finder.nbest(bigram_measures.chi_sq, 10))\n",
    "print()\n",
    "print(bigram_finder.nbest(bigram_measures.likelihood_ratio, 10))\n",
    "print()\n",
    "print(bigram_finder.nbest(bigram_measures.student_t, 10))\n",
    "print()\n",
    "print(trigram_finder.nbest(trigram_measures.pmi, 10))\n",
    "print()\n",
    "print(trigram_finder.nbest(trigram_measures.chi_sq, 10))\n",
    "print()\n",
    "print(trigram_finder.nbest(trigram_measures.likelihood_ratio, 10))\n",
    "print()\n",
    "print(trigram_finder.nbest(trigram_measures.student_t, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It work similarly for tagged words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/kmw/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('$115,000', 'NOUN'), ('annually', 'ADV')), (('$157,460', 'NOUN'), ('yearly', 'ADV')), (('100,000', 'NUM'), ('recipients', 'NOUN')), (('12,000', 'NUM'), ('babies', 'NOUN')), (('1311', 'NUM'), ('acre', 'NOUN')), (('1409', 'NUM'), ('SW', 'NOUN')), (('182', 'NUM'), ('scholastics', 'NOUN')), (('330', 'NUM'), ('Woodland', 'NOUN')), (('3646', 'NUM'), ('N.', 'ADJ')), (('Abe', 'NOUN'), ('Stark', 'NOUN'))]\n",
      "[('X', 'X'), ('PRON', 'VERB'), ('PRT', 'VERB'), ('.', 'PRON'), ('ADP', 'DET'), ('DET', 'ADJ'), ('ADV', 'ADV'), ('ADP', 'NUM'), ('ADJ', 'X'), ('VERB', 'ADV')]\n"
     ]
    }
   ],
   "source": [
    "nltk.download('universal_tagset')\n",
    "\n",
    "bigram_finder = BigramCollocationFinder.from_words(brown.tagged_words(brown.fileids()[0:10], tagset='universal'))\n",
    "\n",
    "print(bigram_finder.nbest(bigram_measures.pmi, 10))\n",
    "\n",
    "bigram_finder = BigramCollocationFinder.from_words(t for w, t in brown.tagged_words(brown.fileids()[0:10], tagset='universal'))\n",
    "\n",
    "print(bigram_finder.nbest(bigram_measures.pmi, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to apply filters to the finder objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('$115,000', 'annually'), ('$157,460', 'yearly'), ('100,000', 'recipients'), ('12,000', 'babies'), ('1311', 'acre'), ('1409', 'SW'), ('182', 'scholastics'), ('330', 'Woodland'), ('Abe', 'Stark'), ('Al', 'Ullman')]\n",
      "\n",
      "[('Latin', 'America'), ('Feb.', '9'), ('U.', 'S.'), ('railroad', 'retirement'), ('rescue', 'trucks'), ('semester', 'hours'), ('Central', 'Falls'), ('Citizens', 'Group'), ('Eastwick', 'Corp.'), ('Pathet', 'Lao')]\n",
      "\n",
      "[('United', 'States'), ('per', 'cent'), ('White', 'House'), ('social', 'security'), ('civil', 'defense'), ('last', 'year'), ('Rhode', 'Island'), ('New', 'Jersey'), ('home', 'rule'), ('Soviet', 'Union')]\n",
      "\n",
      "[('United', 'Nations'), ('United', 'States')]\n"
     ]
    }
   ],
   "source": [
    "bigram_finder = BigramCollocationFinder.from_words(brown.words(brown.fileids()[0:10]))\n",
    "print(bigram_finder.nbest(bigram_measures.pmi, 10))\n",
    "print()\n",
    "bigram_finder.apply_freq_filter(3)\n",
    "print(bigram_finder.nbest(bigram_measures.pmi, 10))\n",
    "print()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "bigram_finder.apply_word_filter(lambda w: (not w.isalpha()) or w.lower() in stopwords.words('english'))\n",
    "print(bigram_finder.nbest(bigram_measures.likelihood_ratio, 10))\n",
    "print()\n",
    "bigram_finder.apply_ngram_filter(lambda *w: 'United' not in w)\n",
    "print(bigram_finder.nbest(bigram_measures.pmi, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practical session!\n",
    "1. Load our own corpus (e.g. [Gutenberg](http://web.eecs.umich.edu/~lahiri/gutenberg_dataset.html)).\n",
    "2. Annotate it.\n",
    "3. Determine some collocations. (Using lemmata and maybe even dependencies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LINCOLN', 'LETTERS'], ['By', 'Abraham', 'Lincoln'], ...]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "corpus_dir = os.path.abspath('corpus/')\n",
    "corpus = nltk.corpus.PlaintextCorpusReader(corpus_dir, '.*Abraham.*\\.txt')\n",
    "print(corpus.sents(corpus.fileids()[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/kmw/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; New York; per cent; Los Angeles; last year; White\n",
      "House; years ago; San Francisco; United Nations; last night; World\n",
      "War; President Kennedy; last week; home runs; Mr. Kennedy; St. Louis;\n",
      "General Assembly; East Greenwich; Viet Nam; New Orleans\n",
      "None\n",
      "Displaying 30 of 108 matches:\n",
      " ADC program in Cook county by a New York City welfare consulting firm , liste\n",
      " of surplus funds of the Port of New York Authority , and making New Jersey at\n",
      "tions , published in yesterday's New York Times . The Mayor said : `` It didn'\n",
      " of the American League champion New York Yankees , who come in here tomorrow \n",
      "two-game weekend series with the New York Yankees . Skinny Brown and Hoyt Wilh\n",
      "helm , plans to bring the entire New York squad here from St. Petersburg , inc\n",
      "rld record earlier this month in New York with a clocking of 1.09.3 , wiped ou\n",
      "March 17 ( AP ) -- Two errors by New York Yankee shortstop Tony Kubek in the e\n",
      "ti , Ohio ( AP ) -- The powerful New York Yankees won their 19th world series \n",
      "th annual dinner and show of the New York Chapter , Baseball Writers' Associat\n",
      "urn of a National League club to New York . Named by Mayor Wagner three years \n",
      "d the Dodgers to California left New York with only the Yankees . Despite coun\n",
      " league , the Continental , with New York as the key franchise . The Continent\n",
      " . Flushing stadium in works The New York franchise is headed by Mrs. Charles \n",
      " born in Manhattan . He attended New York University before switching to Georg\n",
      "C to the majors , from Joplin to New York . With the speed and power of the bo\n",
      "Cancer Research Foundation . The New York Metropolitan Opera Company will be h\n",
      "tengel takes over as boss of the New York Mets , he'll be the only baseballigh\n",
      " ever to wear the uniform of all New York area clubs , past and present : Yank\n",
      "9 miles from Tucson , Ariz. , to New York City : set for influx I can testify \n",
      "nnumerable motels from Tucson to New York boast swimming pools ( `` swim at yo\n",
      ", an American couple formerly of New York City ) . In their suburban cottage t\n",
      "geles , Mrs. Lucy Brett Andrew , New York City , and Mrs. Beatrice Kiefferm , \n",
      "y , and Mrs. Beatrice Kiefferm , New York City , and five grandchildren . Empl\n",
      " months . Mr. Brooks was born in New York , and came to Portland in 1920 . He \n",
      "ars imprisonment on conviction . New York -- ( UPI ) -- The New York Universit\n",
      "ion . New York -- ( UPI ) -- The New York University Board of Trustees has ele\n",
      "do just as good a job as the big New York investment bankers claim only they c\n",
      "r for Isodine Pharmical Corp. of New York . The 33 honored students are : Mike\n",
      " believe we can permit that '' . New York ( AP ) -- Stock market Tuesday stage\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "nltk.download('stopwords')\n",
    "text = nltk.Text(brown.words(brown.fileids()[0:100]))\n",
    "print(text.collocations())\n",
    "print(text.concordance('York', lines=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install `spaCy` models via\n",
    "```shell\n",
    "python -m spacy download en\n",
    "python -m spacy download de\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET DT det\n",
      "quick ADJ JJ amod\n",
      "brown ADJ JJ amod\n",
      "fox NOUN NN nsubj\n",
      "jumps VERB VBZ ROOT\n",
      "over ADP IN prep\n",
      "the DET DT det\n",
      "lazy ADJ JJ amod\n",
      "dog NOUN NN pobj\n",
      ". PUNCT . punct\n",
      "\n",
      "Des PROPN NNP amod\n",
      "kleinen NOUN NN compound\n",
      "Mannes PROPN NNP compound\n",
      "größte VERB VBP compound\n",
      "Freude ADJ JJ compound\n",
      "ist NOUN NN ROOT\n",
      "sein NOUN NN amod\n",
      "Farbfernseher PROPN NNP dobj\n",
      ". PUNCT . punct\n",
      "\n",
      "Jeder PROPN NNP compound\n",
      "Abschied VERB VBD compound\n",
      "ist NOUN NN ROOT\n",
      "ein NOUN NN compound\n",
      "kleiner NOUN NN compound\n",
      "Tod PROPN NNP dobj\n",
      ". PUNCT . punct\n",
      "\n",
      "Ein PROPN NNP compound\n",
      "Mann PROPN NNP compound\n",
      "tanzt NOUN NN nsubj\n",
      "mit NOUN NN ROOT\n",
      "einer NOUN NN compound\n",
      "Frau PROPN NNP dobj\n",
      ". PUNCT . punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk import Tree\n",
    "en_nlp = spacy.load('en')\n",
    "doc = en_nlp(\"The quick brown fox jumps over the lazy dog.\")\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        print(token.orth_, token.pos_, token.tag_, token.dep_)\n",
    "    print()\n",
    "\n",
    "de_nlp = spacy.load('de')\n",
    "doc = en_nlp(\"Des kleinen Mannes größte Freude ist sein Farbfernseher. Jeder Abschied ist ein kleiner Tod. Ein Mann tanzt mit einer Frau.\")\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        print(token.orth_, token.pos_, token.tag_, token.dep_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
